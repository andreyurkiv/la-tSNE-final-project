{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "    Data visualization is one of the most important parts of applied data analysis nowadays. Without proper visualization it’s hard, or sometimes even impossible to inteprete the data in the appropriate way or make reasonable inferences regarding its structure. Dealing with datasets that contain more than 3 attributes start causing problems, because standard visualization techniques doesn’t apply to the data in 4-dimentional space. For humans, it’s even hard to perceive graphical information in 3-dimentional space, that’s why the majority of classical techniqes of data visualization are restricted to two dimentions. It should be noted that one of the main purposes of visualization of high-dimentional datasets is to determine clusters inside the data which may be an important basement for further data analysis.\n",
    "- patterns - more general than clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "    Modern data often contains hundreds or even thousands of features. And classical visualization approaches cannot be used to determine patterns or clusters in it. This is the reason why so many different techniques for visualization high-dimentional data have been proposed. Majority of these techniques merely provide tools to display multidimentional data in two or three-dimentional form and do not give any inferences regarding the inner structure of the data. This severely limits the applicability of those techniques to real-world data, which sometimes contain too much features to reduce them nicely.\n",
    "    \n",
    "    Another approach to this problem lies in the field of dimentionality reduc tion. We can apply classical plotting methods (for example, scatterplots) for the data obtained by decreasing the dimention of the original dataset. Dimen tionality reduction techniques differ substantially from visualization techniques because they are aimed not to make data more visually appealing or understandable, but to preserve as much of the significant structure of the high-dimentional data as possible in its low-dimentional representation [1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Problem setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "    The most important goal of visualization of multidimentional data is to correctly identify clusters of similar data points. This is crucial when we are working on unsupervised learning problem and need to know for sure what number of distict clusters can our dataset be divided in without losing valuable information about inner structure of our data. As we will see in this report, many classical visualization algorithms correctly identify the relationships between data points and position similar ones together. But at the same time from visualizations those algorithms provide it's hard to tell where one class of points ends and other begins (boundaries between classes are not well-defined). And while this is not a problem for small datasets, for large ones it can cause serious obstacles for correct definition of of the number and location of data clusters. t-SNE (t-distributed Stochastic Neighbor Embedding) algorithm aims to provide "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Related work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach to Solution (background/transition/foreground)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start discuss a solution (implementation) of $t$-SNE, let's have a little overview about classic SNE [3 https://papers.nips.cc/paper/2276-stochastic-neighbor-embedding.pdf].\\newline\n",
    "With high-dimensional input spacewe need to transform datapoints in output (usually 2-3 dim.) space. And we can not lose much structure or patterns in our data.\\newline\n",
    "SNE approach is to start with transformation of pairwise Euclidian distance between datapoints into conditional probabilities (similarities).\n",
    "$$ p_{j|i} = \\frac{exp(-||x_i - x_j||^2 / 2 \\sigma_i^2)}{\\sum_{k \\ne i}{exp(-||x_i - x_k||^2 / 2 \\sigma_i^2)}} (1)$$\n",
    "In other words, this formula shows how close $x_j$ point is to $x_i$ one with the Gaussian (varience of $\\sigma$) near $x_j$ datapoint. $\\sigma$ will be different for each point with logic, that where is high density - variance is less. For it it is used metric of perplexity:\n",
    "$$ Perp(P_i) = 2^{H(P_i)} $$\n",
    "$H(P_i)$ is the Shannon entropy of $P_i$ in bits:\n",
    "$$ H(P_i) = -\\sum_j{}p_{j|i} log_2{p_{j|i}} (2)$$\n",
    "Perplexity could be interpret as \"effective count of neighbours for $x_i$\". It is a hyperparameter in $t$-SNE algorithm. $\\sigma$ calculated due to binary search for each $x_i$, $x_j$ pair.\\newline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution (and Discussion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Evaluation  (Plan, Data, Tool, Results, Discussion) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions, Recommendations, and Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
