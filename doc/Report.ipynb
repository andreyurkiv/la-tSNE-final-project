{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Data visualization is one of the most important parts of applied data analysis nowadays. Without proper visualization it’s hard, or sometimes even impossible to inteprete the data in the appropriate way or make reasonable inferences regarding its structure. Dealing with datasets that contain more than 3 attributes start causing problems, because standard visualization techniques doesn’t ap ply to the data in 4-dimentional space. For humans, it’s even hard to perceive graphical information in 3-dimentional space, that’s why the majority of classical techniqes of data visualization are restricted to two dimentions. It should be noted that one of the main purposes of visualization of high-dimentional datasets is to determine clusters inside the data which may be an important basement for further data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Modern data often contains hundreds or even thousands of features. And classical visualization approaches cannot be used to determine patterns or clusters in it. This is the reason why so many different techniques for visualization high-dimentional data have been proposed. Majority of these techniques merely provide tools to display multidimentional data in two or three-dimentional form and do not give any inferences regarding the inner structure of the data. This severely limits the applicability of those techniques to real-world data, which sometimes contain too much features to reduce them nicely.\n",
    "    \n",
    "    Another approach to this problem lies in the field of dimentionality reduc tion. We can apply classical plotting methods (for example, scatterplots) for the data obtained by decreasing the dimention of the original dataset. Dimen tionality reduction techniques differ substantially from visualization techniques because they are aimed not to make data more visually appealing or understandable, but to preserve as much of the significant structure of the high-dimentional data as possible in its low-dimentional representation [1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    The most important goal of visualization of multidimentional data is to correctly identify clusters of similar data points. This is crucial when we are working on unsupervised learning problem and need to know for sure what number of distict clusters can our dataset be divided in without losing valuable information about inner structure of our data. As we will see in this report, many classical visualization algorithms correctly identify the relationships between data points and position similar ones together. But at the same time from visualizations those algorithms provide it's hard to tell where one class of points ends and other begins (boundaries between classes are not well-defined). And while this is not a problem for small datasets, for large ones it can cause serious obstacles for correct definition of of the number and location of data clusters. t-SNE (t-distributed Stochastic Neighbor Embedding) algorithm is aimed to overcome those limitations by identifying the relevant patterns using the approach in which similar objects are modeled by nearby points and dissimilar objects are modeled by disntant points with high probability [2]. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Related work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach to Solution (background/transition/foreground)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution (and Discussion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation  (Plan, Data, Tool, Results, Discussion) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Since t-SNE is primaraly visualization technique, in order to evaluate its performance and visualizational capacity we need to compare visualization produced by t-SNE with the ones obtained using other non-parametric visualization techniques for multidimentional data, such as Multidimentional scaling using SMACOF (Scaling by MAjorizing a COmplicated Function) algorithm, Isomap, Locally Linear Embedding, Principal Components Analysis and Laplacian Eigenmaps. \n",
    "    \n",
    "    In our work we experimented with 2 different datasets: Olivetti faces dataset and handrwitten digits dataset. \n",
    "    \n",
    "    Olivetti faces dataset contains 400 64 x 64 grayscale images of faces (10 images for each of 40 subjects). Those images were taken at different time with different datails varying, such as face expression, lighting and facial details (absence or presence of glasses). They are labeled according to the identity of the person depicted.\n",
    "    \n",
    "    Handwritten digits dataset consists of 1797 8 x 8 grayscale images of handwritten digits of 10 classes. There are nearly 180 instances per digit class in this dataset.\n",
    "    \n",
    "    In the original t-SNE paper [1], the authors use PCA to reduce dimentionality before feeding the data into algorithms that transform it into two-dimentional representation. They are doing it for the purpose of computation efficiency and it absolutely makes sence when we apply those algorithms to large datasets. But since the datasets which we use in our experiements are relatively small, preliminar dimentionality reduction doesn't make much difference in terms of computational costs in our case, so we decided to pass this step up.\n",
    "    \n",
    "    For each of these datasets, there is information about the class of each data point. Class information is only used for visualization purposes and is not considered during calculation of the spatial coordinates of the points in two-dimentional space. We decided to visualize the whole images instead of points because this kind of graph is much more understandable and provides better means of evaluating how well the mapping preserves the similarities within each class.\n",
    "    \n",
    "| Technique           | Parameters                                   |\n",
    "----------------------|-----------------------------------------------\n",
    "| t-SNE               | perplexity = 5, 1000 iterations              |\n",
    "----------------------|-----------------------------------------------\n",
    "| MDS (SMACOF)        | none                                         |   \n",
    "----------------------|-----------------------------------------------\n",
    "| Isomap              | neighbors = 5                                |\n",
    "----------------------|-----------------------------------------------\n",
    "| LLE                 | neighbors = 12                               |\n",
    "----------------------|-----------------------------------------------\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions, Recommendations, and Future Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
